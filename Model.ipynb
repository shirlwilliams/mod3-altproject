{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mod 3 Project - Customer Churn Data\n",
    "Build a classifier to predict whether a customer will (\"soon\") stop doing business with SyriaTel, a telecommunications company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools  \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "import functions as fc\n",
    "from importlib import reload\n",
    "reload(fc)\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm, tree\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the dataset and preview\n",
    "raw_df = pd.read_csv('bigml_59c28831336c6604c800002a.csv')\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning using function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_cleaner(col, bad_characters='()*&^@#$%'):\n",
    "    for ch in bad_characters:\n",
    "        col = col.replace(ch, \" \")\n",
    "        col = col.replace(\" \", \"_\")\n",
    "        col = col.lower()\n",
    "        return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_df.rename(mapper=column_cleaner, axis=1, inplace=True)\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.churn.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of all features\n",
    "cat_df = raw_df.drop(columns='churn')\n",
    "g = cat_df.hist(figsize=(23, 20), color='salmon')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most columns are fairly normal except number_vmail_messages has too many 0 values.<br>\n",
    "Categorical values:\n",
    "* state\n",
    "* area code       \n",
    "* international plan    \n",
    "* voice mail plan   <br><br>\n",
    "\n",
    "## Churn Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of churn data\n",
    "ax = raw_df.churn.value_counts().plot(kind='barh', color='navajowhite')\n",
    "\n",
    "# create a list to collect the plt.patches data\n",
    "totals = []\n",
    "\n",
    "# find the values and append to list\n",
    "for i in ax.patches:\n",
    "    totals.append(i.get_width())\n",
    "\n",
    "# set individual bar lables using above list\n",
    "total = sum(totals)\n",
    "\n",
    "# set individual bar lables using above list\n",
    "for i in ax.patches:\n",
    "    # get_width pulls left or right; get_y pushes up or down\n",
    "    ax.text(i.get_width()+.3, i.get_y()+.38, \\\n",
    "            str(round((i.get_width()/total)*100, 2))+'%')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.title('Churn')\n",
    "plt.xlabel('Counts')\n",
    "plt.ylabel('Values')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out of the box baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(raw_df, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.drop(columns=['churn', 'phone_number', 'state', 'international_plan', 'voice_mail_plan'], axis=1)\n",
    "y_train = df_train.churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initially take out categorical variables\n",
    "x_test = df_test.drop(columns=['churn', 'phone_number', 'state', 'international_plan', 'voice_mail_plan'], axis=1)\n",
    "y_test = df_test.churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(x_test,y_test), clf.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_filename = './models/rf_bc.pkl'\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(clf, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle categorical variables\n",
    "* The area code is already numerical.\n",
    "* I believe the state is not needed at this time. It will be dropped.\n",
    "* I need to encode international_plan and voice_mail_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop state and phone number\n",
    "df = raw_df.drop(columns=['state', 'phone_number'])\n",
    "\n",
    "# Change the categorical variables to numbers\n",
    "df.international_plan = df.international_plan.replace('yes', 1).replace('no', 0)\n",
    "df.voice_mail_plan = df.voice_mail_plan.replace('yes', 1).replace('no', 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try other models\n",
    "\n",
    "I will explore several models for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Dependent and Independent Datasets based on our Dependent #and Independent features\n",
    "X = df.drop(columns='churn')\n",
    "y = raw_df.churn\n",
    "\n",
    "#Split the Data into Training and Testing sets with test size as #30%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate models and provide a collection for the results \n",
    "classifiers = []\n",
    "\n",
    "xg_clf = xgboost.XGBClassifier()\n",
    "classifiers.append(xg_clf)\n",
    "\n",
    "svm_clf = svm.SVC()\n",
    "classifiers.append(svm_clf)\n",
    "\n",
    "dtree_clf = tree.DecisionTreeClassifier()\n",
    "classifiers.append(dtree_clf)\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "classifiers.append(rf_clf)\n",
    "\n",
    "ab_clf = AdaBoostClassifier()\n",
    "classifiers.append(ab_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit, train, and test the models\n",
    "for mod in [xg_clf, svm_clf, dtree_clf, rf_clf, ab_clf]:\n",
    "    mod.fit(X_train, y_train)\n",
    "    train_score = mod.score(X_train, y_train)\n",
    "    test_score = mod.score(X_test, y_test)\n",
    "    print(train_score, test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score indicators\n",
    "* The XGBoost score looks promising (0.972, 0.953). \n",
    "* The Random Forest score changed from (0.918, 0.988) to (0.992, 0.953) showing improvement.\n",
    "* However, SVM and Decision Tree appear to be overfitting.\n",
    "* The AdaBoost score, though not as high, appears to be more consistent with the train/test scores (0.885, 0.885)\n",
    "<br><br>\n",
    "### Let's look at the confusion matrix for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at scores and the confusion matrix\n",
    "\n",
    "# List to collect scores for easier reading\n",
    "matrices = []\n",
    "accuracy = []\n",
    "\n",
    "# Loop for accuracy scores and confusion matrices\n",
    "for mod in [xg_clf, svm_clf, dtree_clf, rf_clf, ab_clf]:\n",
    "    \n",
    "    mod.fit(X_train, y_train)\n",
    "    y_pred = mod.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy of %s is %s\"%(mod, acc))\n",
    "    accuracy.append(acc)\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix of %s is %s\"%(mod, cm))\n",
    "    matrices.append(cm)\n",
    "    \n",
    "    print('Confusion Matrix')\n",
    "    sns.heatmap(cm/np.sum(cm), annot=True, fmt='.2%', cmap='YlGnBu')\n",
    "    plt.autoscale()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collection for easier reading\n",
    "models = [xg_clf, svm_clf, dtree_clf, rf_clf, ab_clf]\n",
    "for (mod, arr) in zip(models, matrices):\n",
    "    model = str(mod)[:3]\n",
    "    print(str(model) + ': \\n' + str(np.matrix(arr)))\n",
    "display('Accuracy scores: ' + str(accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XGBoost has a slightly higher predictive score and the confusion matrix holds slightly more true positives and true negatives than the Random Forest Model. We'll use the XGBoost as the model. Additionally it minimizes the false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model interpretation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost for Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the feature importances\n",
    "display(xg_clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "fig = go.Figure(go.Bar(\n",
    "            x=xg_clf.feature_importances_.sort(),\n",
    "            y=X_train.columns,\n",
    "            marker_color='salmon',\n",
    "            orientation='h'));\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Important Features of XGBoost Model\",\n",
    "        'y':0.9,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'},\n",
    "    xaxis_title=\"Feature Score\",\n",
    "    yaxis_title=\"Features\",\n",
    "    xaxis={\n",
    "        'categoryorder':'total ascending'})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crazy Observation - See how the features increase in importance in a linear fashion.<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indicated Feature Exploration\n",
    "Let's look more closely at the top features of customer service calls and total international calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"customer_service_call\", y=\"churn\", data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set predictions\n",
    "pred = xg_clf.predict(X_test)\n",
    "\n",
    "# Confusion matrix and classification report\n",
    "print('\\t\\tClassification Report')\n",
    "print()\n",
    "print(classification_report(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    print('Confusion Matrix')\n",
    "    sns.heatmap(cm/np.sum(cm), annot=True, fmt='.2%', cmap='BuPu')\n",
    "    plt.autoscale()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_filename = './models/rf_model.pkl'\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(xg_clf, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance Caveat\n",
    "According to the article (link below) there are actually 3 measures for finding important features using 'importance type': cover, gain, and the default value weight.<br><br>\n",
    "https://towardsdatascience.com/interpretable-machine-learning-with-xgboost-9ec80d148d27<br><br>\n",
    "Let's explore the three importance types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Explore Feature Importance\n",
    "for item in ['weight', 'gain', 'cover']:\n",
    "    xgboost.plot_importance(xg_clf, importance_type=item)\n",
    "    plt.title('XGBoost Importance Plot using ' + item.title())\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Extensions\n",
    "Other features to consider providing:\n",
    "* customer features: basic information about the customer (e.g., age, income, house value, college education)\n",
    "* support features: characterizations of the customer’s interactions with customer support (e.g., number of interactions, topics of questions asked, satisfaction ratings)\n",
    "* usage features: characterizations of the customer’s usage of the service\n",
    "* contextual features: any other contextual information we have about the customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
